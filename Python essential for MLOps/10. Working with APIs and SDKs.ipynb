{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with APIs and SDKs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APis and SDKs are tools that you will be most likely interact when you are building automation, interacting with the Cloud, trying to put everything together and help your ML operations environment to produce something that is reusable and automated and they will enhance and increase your confidence because of all of the automation.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Azure Command-Line Interface (CLI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After install Azure CLI (https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli), you can check from termianl:\n",
    "\n",
    "* az --version: to see the version of azure-cli that is install.\n",
    "* az extension list: to list the extensions that are installed.\n",
    "* az extension add -n ml -y: to add the ml extension, that would allow to connect to machinery studio.\n",
    "* az ml --help: to obtain help about ml extension.\n",
    "* az login\n",
    "\n",
    "Additionally, in the environment is neccesary to install azureml-core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AzureML Studio with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import creds\n",
    "import azure.core\n",
    "\n",
    "from azureml.core import Workspace, Environment\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "resource_name = \"Demo_RS\"\n",
    "workspace_name = \"Demo_WS\"\n",
    "aml_compute_target = \"demo-cluster\"\n",
    "experiment_name = \"demo_experiment\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the workspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the previously created configuration file to create the Azure ML workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(\"Workspace is already exist\")\n",
    "except:\n",
    "    ws = Workspace.create(workspace_name,\n",
    "                          resource_group = resource_name,\n",
    "                          create_resource_group = True,\n",
    "                          subscription_id = creds.subscription_id,\n",
    "                          location = \"East US\")\n",
    "    ws.write_config(\".azureml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "# Create compute target\n",
    "\n",
    "try:\n",
    "    aml_compute: AmlCompute(ws, aml_compute_target)\n",
    "    print(\"This compute target already exist\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target :\", aml_compute_target)\n",
    "\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1,\n",
    "                                                                max_nodes = 4,\n",
    "                                                                idle_seconds_before_scaledown = 3000)\n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "\n",
    "print(\"Azure ML compute attached now\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destro workspace and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el kernel porque no se pudo cargar un archivo DLL.\n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/kernelFailuresDllLoad'>aquí</a> para obtener más información."
     ]
    }
   ],
   "source": [
    "ws.delete(delete_dependent_resources = True, no_wait = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face is a compnany that builds a lot of APIs and packages for ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c534a0c858420399a4cbc62e7394a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a4e15a90c04e7e956123fecc40a1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4214bf1c62e54fdc9902db0d59c3da3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09969c9bc8b8453c8530f4a53a44848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e97abfe2a194478994967904e950dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text2text-generation\", model =\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'machine learning is often seen as the ultimate goal in production . a foundational process that'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize\n",
    "generator(\"summarize: Machine Learning in production environmnets is largely seen as the ultimate goal. Sometimes, deployin models can be difficult when automation is not part of the workflow. Creating a foundational process that is reliable and automated is complex and requires commitment from the team and the organizations as a whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'positive'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment\n",
    "generator(\"sst2 sentence: Automation takes hard work but allows you to have a solid deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'not_entailment'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions\n",
    "generator(\"question: Is deploying models into production hard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"L'automatisation exige beaucoup de travail, mais vous permet d'avoir un dé\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation\n",
    "generator(\"translate English to French: Automation takes hard work but allows you to have a solid deployment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create other generation objects by calling in other models as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380248eed68c426db6065bce708a2245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03511b2c8a4a441f8cdf7e8add9f41da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c070d95be90c4f0090b82317c141e952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c317faf35f594ebf805594c0a07a2d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aee7c9812de45ca8d8d3ae3b379cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39194d5708c4a4096f13ca830bd5ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt2_generator = pipeline(\"text-generation\", model = \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The future of computational pathology will likely involve more rapid advances in medical imaging, neurobiology, and molecular therapy.\\n\\nThere will be a large population of medical patients with no history of neurologic disease who will need specialized surgery that does NOT require invasive brain scans. In addition to the need for specialized procedures, a large population of new patients will require special training to deal with these procedures, but the general practitioner should certainly not be able to use this kind of training unless the patient has an ongoing history of neurodegenerative conditions, such as Parkinson's condition, as per the recommendations of the European Alzheimer's Society.\\n\\n. The American Academy of Neurology and American School for Neuroscience, which has approved this plan, has been lobbying the FDA to postpone the adoption of a computerized clinical-trial protocol that is now in the public hands. Although no one knows how long it will take for this procedure (for this, let's just hope that the time it takes for the FDA to issue a license is less than a month (and let's also pray for the FDA's eventual decision not to intervene in the situation), it would be good for a potential future patient to have a standardised approach to the diagnosis of neurodegenerative diseases such as autism or Alzheimer's disease, and to use these treatments as soon as possible after diagnosis. A common concern is the possibility of requiring only cognitively-related features (e.g. hearing loss, learning difficulty, memory deficits), or with more specific diagnoses such as schizophrenia or Alzheimer's disease, which may require much longer follow-up tests, such as MRI.\\n\\nThe idea that cognitive diseases will become treatable early enough to address before the medical community becomes blinded by the FDA's failure to provide accurate research is a myth.\\n\\nAs noted in Part I earlier, the American Academy of Neurology recommends that we continue to have medical and surgical treatments that are targeted at the treatment of Alzheimer disease, not Alzheimer's disease. Therefore, such a rule is in no way reflective of our own medical community's current understanding of the impact of other diseases on the health of people.\\n\\nA number of studies published recently (see IBD) have indicated that brain disorders do not arise from biological differences. However, few neurologists have addressed the cognitive deficits at the molecular level in non-nursing adults, or the neurodegenerative diseases for which dementia is common. As such, we are working to develop methods that can address these cognitive deficits and, if feasible, better understand their origin and consequences. This\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_generator(\"The future of computational pathology\", max_new_tokens = 512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggings Face Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other core piece of the Hugging Face libraries are the datasets. It is a library for loading datasets dynamically, similar to other dynamic loading libraries.\n",
    "\n",
    "It allows you to retrieve dynamically any dataset that is in Huggin Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63799\n",
      "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity', 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'americas_nli', 'ami', 'amttl', 'anli', 'app_reviews', 'aqua_rat', 'aquamuse', 'ar_res_reviews', 'ar_sarcasm', 'arabic_billion_words', 'arabic_pos_dialect', 'arabic_speech_corpus', 'arcd', 'arsentd_lev', 'art', 'arxiv_dataset', 'ascent_kb', 'aslg_pc12', 'asnq', 'asset', 'assin', 'assin2', 'atomic', 'autshumato', 'banking77', 'bbaw_egyptian', 'bbc_hindi_nli', 'bc2gm_corpus', 'beans', 'best2009', 'bianet', 'bible_para', 'big_patent', 'billsum', 'bing_coronavirus_query_set', 'biomrc', 'biosses', 'blbooks', 'blbooksgenre', 'blended_skill_talk', 'blimp', 'blog_authorship_corpus', 'bn_hate_speech', 'bnl_newspapers', 'bookcorpus', 'bookcorpusopen', 'boolq', 'bprec', 'break_data', 'brwac', 'bsd_ja_en', 'bswac', 'c3', 'c4', 'cail2018', 'caner', 'capes', 'casino', 'catalonia_independence', 'cats_vs_dogs', 'cawac', 'cbt', 'cc100', 'cc_news', 'ccaligned_multilingual', 'cdsc', 'cdt', 'cedr', 'cfq', 'chr_en', 'cifar10', 'cifar100', 'circa', 'civil_comments', 'clickbait_news_bg', 'climate_fever', 'clinc_oos', 'clue', 'cmrc2018', 'cmu_hinglish_dog', 'cnn_dailymail', 'coached_conv_pref', 'coarse_discourse', 'codah', 'code_search_net', 'code_x_glue_cc_clone_detection_big_clone_bench', 'code_x_glue_cc_clone_detection_poj104', 'code_x_glue_cc_cloze_testing_all', 'code_x_glue_cc_cloze_testing_maxmin', 'code_x_glue_cc_code_completion_line', 'code_x_glue_cc_code_completion_token', 'code_x_glue_cc_code_refinement', 'code_x_glue_cc_code_to_code_trans', 'code_x_glue_cc_defect_detection', 'code_x_glue_ct_code_to_text', 'code_x_glue_tc_nl_code_search_adv', 'code_x_glue_tc_text_to_code', 'code_x_glue_tt_text_to_text', 'com_qa', 'common_gen', 'common_language', 'common_voice', 'commonsense_qa', 'competition_math', 'compguesswhat', 'conceptnet5', 'conll2000', 'conll2002', 'conll2003', 'conllpp', 'consumer-finance-complaints', 'conv_ai', 'conv_ai_2', 'conv_ai_3', 'conv_questions', 'coqa', 'cornell_movie_dialog', 'cos_e', 'cosmos_qa', 'counter', 'covid_qa_castorini', 'covid_qa_deepset', 'covid_qa_ucsd', 'covid_tweets_japanese', 'covost2', 'cppe-5', 'craigslist_bargains', 'crawl_domain', 'crd3', 'crime_and_punish', 'crows_pairs', 'cryptonite', 'cs_restaurants', 'cuad', 'curiosity_dialogs', 'daily_dialog', 'dane', 'danish_political_comments', 'dart', 'datacommons_factcheck', 'dbpedia_14', 'dbrd', 'deal_or_no_dialog', 'definite_pronoun_resolution', 'dengue_filipino', 'dialog_re', 'diplomacy_detection', 'disaster_response_messages', 'discofuse', 'discovery', 'disfl_qa', 'doc2dial', 'docred', 'doqa', 'dream', 'drop', 'duorc', 'dutch_social', 'dyk', 'e2e_nlg', 'e2e_nlg_cleaned', 'ecb', 'ecthr_cases', 'eduge', 'ehealth_kd', 'eitb_parcc', 'electricity_load_diagrams', 'eli5', 'eli5_category', 'emea', 'emo', 'emotone_ar', 'empathetic_dialogues', 'enriched_web_nlg', 'eraser_multi_rc', 'esnli', 'eth_py150_open', 'ethos', 'eu_regulatory_ir', 'eurlex', 'euronews', 'europa_eac_tm', 'europa_ecdc_tm', 'europarl_bilingual', 'event2Mind', 'evidence_infer_treatment', 'exams', 'factckbr', 'fake_news_english', 'fake_news_filipino', 'farsi_news', 'fashion_mnist', 'fever', 'few_rel', 'financial_phrasebank', 'finer', 'flores', 'flue', 'food101', 'fquad', 'freebase_qa', 'gap', 'gem', 'generated_reviews_enth', 'generics_kb', 'german_legal_entity_recognition', 'germaner', 'germeval_14', 'giga_fren', 'gigaword', 'glucose', 'glue', 'gnad10', 'go_emotions', 'gooaq', 'google_wellformed_query', 'grail_qa', 'great_code', 'greek_legal_code', 'guardian_authorship', 'gutenberg_time', 'hans', 'hansards', 'hard', 'harem', 'has_part', 'hate_offensive', 'hate_speech18', 'hate_speech_filipino', 'hate_speech_offensive', 'hate_speech_pl', 'hate_speech_portuguese', 'hatexplain', 'hausa_voa_ner', 'hausa_voa_topics', 'hda_nli_hindi', 'head_qa', 'health_fact', 'hebrew_projectbenyehuda', 'hebrew_sentiment', 'hebrew_this_world', 'hellaswag', 'hind_encorp', 'hindi_discourse', 'hippocorpus', 'hkcancor', 'hlgd', 'hope_edi', 'hotpot_qa', 'hover', 'hrenwac_para', 'hrwac', 'humicroedit', 'hybrid_qa', 'hyperpartisan_news_detection', 'iapp_wiki_qa_squad', 'id_clickbait', 'id_liputan6', 'id_nergrit_corpus', 'id_newspapers_2018', 'id_panl_bppt', 'id_puisi', 'igbo_english_machine_translation', 'igbo_monolingual', 'igbo_ner', 'ilist', 'imdb', 'imdb_urdu_reviews', 'imppres', 'indic_glue', 'indonli', 'inquisitive_qg', 'interpress_news_category_tr', 'interpress_news_category_tr_lite', 'irc_disentangle', 'isixhosa_ner_corpus', 'isizulu_ner_corpus', 'iwslt2017', 'jeopardy', 'jfleg', 'jigsaw_toxicity_pred', 'jigsaw_unintended_bias', 'jnlpba', 'journalists_questions', 'kan_hope', 'kannada_news', 'kd_conv', 'kde4', 'kelm', 'kilt_tasks', 'kilt_wikipedia', 'kinnews_kirnews', 'klue', 'kor_3i4k', 'kor_hate', 'kor_ner', 'kor_nli', 'kor_nlu', 'kor_qpair', 'kor_sae', 'kor_sarcasm', 'labr', 'lama', 'lambada', 'large_spanish_corpus', 'laroseda', 'lc_quad', 'lener_br', 'lex_glue', 'liar', 'librispeech_asr', 'librispeech_lm', 'limit', 'lince', 'linnaeus', 'liveqa', 'lj_speech', 'lm1b', 'lst20', 'm_lama', 'mac_morpho', 'makhzan', 'masakhaner', 'math_dataset', 'math_qa', 'matinf', 'mbpp', 'mc4', 'mc_taco', 'md_gender_bias', 'mdd', 'med_hop', 'medal', 'medical_dialog', 'medical_questions_pairs', 'menyo20k_mt', 'meta_woz', 'metooma', 'metrec', 'miam', 'mkb', 'mkqa', 'mlqa', 'mlsum', 'mnist', 'mocha', 'moroco', 'movie_rationales', 'mrqa', 'ms_marco', 'ms_terms', 'msr_genomics_kbcomp', 'msr_sqa', 'msr_text_compression', 'msr_zhen_translation_parity', 'msra_ner', 'mt_eng_vietnamese', 'muchocine', 'multi_booked', 'multi_eurlex', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'multi_para_crawl', 'multi_re_qa', 'multi_woz_v22', 'multi_x_science_sum', 'multidoc2dial', 'multilingual_librispeech', 'mutual_friends', 'mwsc', 'myanmar_news', 'narrativeqa', 'narrativeqa_manual', 'natural_questions', 'ncbi_disease', 'nchlt', 'ncslgr', 'nell', 'neural_code_search', 'news_commentary', 'newsgroup', 'newsph', 'newsph_nli', 'newspop', 'newsqa', 'newsroom', 'nkjp-ner', 'nli_tr', 'nlu_evaluation_data', 'norec', 'norne', 'norwegian_ner', 'nq_open', 'nsmc', 'numer_sense', 'numeric_fused_head', 'oclar', 'offcombr', 'offenseval2020_tr', 'offenseval_dravidian', 'ofis_publik', 'ohsumed', 'ollie', 'omp', 'onestop_english', 'onestop_qa', 'open_subtitles', 'openai_humaneval', 'openbookqa', 'openslr', 'opinosis', 'opus100', 'opus_books', 'opus_dgt', 'opus_dogc', 'opus_elhuyar', 'opus_euconst', 'opus_finlex', 'opus_fiskmo', 'opus_gnome', 'opus_infopankki', 'opus_memat', 'opus_montenegrinsubs', 'opus_openoffice', 'opus_paracrawl', 'opus_rf', 'opus_tedtalks', 'opus_ubuntu', 'opus_wikipedia', 'opus_xhosanavy', 'orange_sum', 'oscar', 'para_crawl', 'para_pat', 'parsinlu_reading_comprehension', 'pass', 'paws-x', 'paws', 'pec', 'peoples_daily_ner', 'per_sent', 'persian_ner', 'pg19', 'php', 'pib', 'piqa', 'pn_summary', 'poem_sentiment', 'polemo2', 'poleval2019_cyberbullying', 'poleval2019_mt', 'polsum', 'polyglot_ner', 'prachathai67k', 'pragmeval', 'proto_qa', 'psc', 'ptb_text_only', 'pubmed', 'pubmed_qa', 'py_ast', 'qa4mre', 'qa_srl', 'qa_zre', 'qangaroo', 'qanta', 'qasc', 'qed', 'qed_amara', 'quac', 'quail', 'quarel', 'quartz', 'quora', 'quoref', 'race', 're_dial', 'reasoning_bg', 'recipe_nlg', 'reclor', 'red_caps', 'reddit_tifu', 'refresd', 'reuters21578', 'riddle_sense', 'ro_sent', 'ro_sts', 'ro_sts_parallel', 'roman_urdu', 'ronec', 'ropes', 'rotten_tomatoes', 'samsum', 'sanskrit_classic', 'saudinewsnet', 'sberquad', 'scan', 'scb_mt_enth_2020', 'scene_parse_150', 'schema_guided_dstc8', 'scielo', 'scientific_papers', 'sciq', 'scitail', 'search_qa', 'sede', 'selqa', 'sem_eval_2010_task_8', 'sem_eval_2014_task_1', 'sem_eval_2018_task_1', 'sem_eval_2020_task_11', 'sent_comp', 'senti_lex', 'senti_ws', 'sentiment140', 'sepedi_ner', 'sesotho_ner_corpus', 'setimes', 'setswana_ner_corpus', 'sharc', 'sharc_modified', 'sick', 'silicone', 'simple_questions_v2', 'siswati_ner_corpus', 'smartdata', 'sms_spam', 'snips_built_in_intents', 'snli', 'snow_simplified_japanese_corpus', 'so_stacksample', 'social_bias_frames', 'social_i_qa', 'sofc_materials_articles', 'sogou_news', 'spanish_billion_words', 'spc', 'species_800', 'speech_commands', 'spider', 'squad', 'squad_adversarial', 'squad_es', 'squad_it', 'squad_kor_v1', 'squad_kor_v2', 'squad_v1_pt', 'squad_v2', 'squadshifts', 'srwac', 'sst', 'stereoset', 'story_cloze', 'stsb_mt_sv', 'stsb_multi_mt', 'style_change_detection', 'subjqa', 'super_glue', 'superb', 'svhn', 'swag', 'swahili', 'swahili_news', 'swda', 'swedish_medical_ner', 'swedish_ner_corpus', 'swedish_reviews', 'tab_fact', 'tamilmixsentiment', 'tanzil', 'tapaco', 'tashkeela', 'taskmaster1', 'taskmaster2', 'taskmaster3', 'tatoeba', 'ted_hrlr', 'ted_iwlst2013', 'ted_multi', 'ted_talks_iwslt', 'telugu_books', 'telugu_news', 'tep_en_fa_para', 'text2log', 'thai_toxicity_tweet', 'thainer', 'thaiqa_squad', 'thaisum', 'the_pile_books3', 'the_pile_openwebtext2', 'the_pile_stack_exchange', 'tilde_model', 'time_dial', 'times_of_india_news_headlines', 'timit_asr', 'tiny_shakespeare', 'tlc', 'tmu_gfm_dataset', 'told-br', 'totto', 'trec', 'trivia_qa', 'tsac', 'ttc4900', 'tunizi', 'tuple_ie', 'turk', 'turkic_xwmt', 'turkish_movie_sentiment', 'turkish_ner', 'turkish_product_reviews', 'turkish_shrinked_ner', 'turku_ner_corpus', 'tweet_eval', 'tweet_qa', 'tweets_ar_en_parallel', 'tweets_hate_speech_detection', 'twi_text_c3', 'twi_wordsim353', 'tydiqa', 'ubuntu_dialogs_corpus', 'udhr', 'um005', 'un_ga', 'un_multi', 'un_pc', 'universal_dependencies', 'universal_morphologies', 'urdu_fake_news', 'urdu_sentiment_corpus', 'vctk', 'vivos', 'web_nlg', 'web_of_science', 'web_questions', 'weibo_ner', 'wi_locness', 'wider_face', 'wiki40b', 'wiki_asp', 'wiki_atomic_edits', 'wiki_auto', 'wiki_bio', 'wiki_dpr', 'wiki_hop', 'wiki_lingua', 'wiki_movies', 'wiki_qa', 'wiki_qa_ar', 'wiki_snippets', 'wiki_source', 'wiki_split', 'wiki_summary', 'wikiann', 'wikicorpus', 'wikihow', 'wikipedia', 'wikisql', 'wikitext', 'wikitext_tl39', 'wili_2018', 'wino_bias', 'winograd_wsc', 'winogrande', 'wiqa', 'wisesight1000', 'wisesight_sentiment', 'wmt14', 'wmt15', 'wmt16', 'wmt17', 'wmt18', 'wmt19', 'wmt20_mlqe_task1', 'wmt20_mlqe_task2', 'wmt20_mlqe_task3', 'wmt_t2t', 'wnut_17', 'wongnai_reviews', 'woz_dialogue', 'wrbsc', 'x_stance', 'xcopa', 'xcsr', 'xed_en_fi', 'xglue', 'xnli', 'xor_tydi_qa', 'xquad', 'xquad_r', 'xsum', 'xsum_factuality', 'xtreme', 'yahoo_answers_qa', 'yahoo_answers_topics', 'yelp_polarity', 'yelp_review_full', 'yoruba_bbc_topics', 'yoruba_gv_ner', 'yoruba_text_c3', 'yoruba_wordsim353', 'youtube_caption_corrections', 'zest', 'elkarhizketak', 'wikitablequestions', 'conll2012_ontonotesv5', 'monash_tsf', 'roman_urdu_hate_speech', 'adv_glue', 'metashift', 'gsm8k', 'sbu_captions', 'conceptual_captions', 'conceptual_12m', 'visual_genome', 'imagenet-1k', 'tne', 'textvqa', 'ett', 'medmcqa', 'imagenet_sketch', 'biwi_kinect_head_pose', 'enwik8', 'truthful_qa', 'bigbench', 'quickdraw', 'sst2', 'lccc']\n"
     ]
    }
   ],
   "source": [
    "# Explore available datasets\n",
    "available = list_datasets()\n",
    "print(len(available))\n",
    "print([i for i in available if '/' not in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5987bcce854b07b14d0aa90b775a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421c6eee31444db68f2b53cae47b47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset movie_rationales/default (download: 3.72 MiB, generated: 8.33 MiB, post-processed: Unknown size, total: 12.04 MiB) to C:\\Users\\ADMIN\\.cache\\huggingface\\datasets\\movie_rationales\\default\\0.1.0\\70ed6b72496c90835e8ee73ebf8d0e49f5ad3aa93f302c8a4b6c886143cfb779...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4013ddcfdbea4ffaac96787f76d51fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11ee2d891d345568d49d199be784468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e984013d1d4390968882d05f98dd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4603390332b14946a342a8701f92ecf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset movie_rationales downloaded and prepared to C:\\Users\\ADMIN\\.cache\\huggingface\\datasets\\movie_rationales\\default\\0.1.0\\70ed6b72496c90835e8ee73ebf8d0e49f5ad3aa93f302c8a4b6c886143cfb779. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc33fbd48f984a7cb44022ce8a30238d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset dynamically by passing the name\n",
    "movie_rationales = load_dataset(\"movie_rationales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 1600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'label', 'evidences'],\n",
       "        num_rows: 199\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The object is a dict-like mapping of actual datasets\n",
    "movie_rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>evidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mind - fuck movie, the sad part is, downshift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard 's quick movie review damn\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it 's pretty much a sunken ship, sutherland i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[the characters and acting is nothing spectacu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . '\\nfirs...</td>\n",
       "      <td>0</td>\n",
       "      <td>[dead on arrival, the characters stink, subpar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it is highly derivative and somewhat boring, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>capsule : in 2176 on the planet mars police ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sadly what follows is not really up to the bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>so ask yourself what \" 8 mm \" ( \" eight millim...</td>\n",
       "      <td>0</td>\n",
       "      <td>[probably not, tags on a ridiculous self - rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that 's exactly how long the movie felt to me ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nasty but unamusing joke, is annoying, they c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>call it a road trip for the walking wounded .\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>[a sentimental and painfully mundane european ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>plot : a young french boy sees his parents kil...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it 's not original , is entirely predictable ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  plot : two teen couples go to a church party ,...      0   \n",
       "1  the happy bastard 's quick movie review damn\\n...      0   \n",
       "2  it is movies like these that make a jaded movi...      0   \n",
       "3  \" quest for camelot \" is warner bros . '\\nfirs...      0   \n",
       "4  synopsis : a mentally unstable man undergoing ...      0   \n",
       "5  capsule : in 2176 on the planet mars police ta...      0   \n",
       "6  so ask yourself what \" 8 mm \" ( \" eight millim...      0   \n",
       "7  that 's exactly how long the movie felt to me ...      0   \n",
       "8  call it a road trip for the walking wounded .\\...      0   \n",
       "9  plot : a young french boy sees his parents kil...      0   \n",
       "\n",
       "                                           evidences  \n",
       "0  [mind - fuck movie, the sad part is, downshift...  \n",
       "1  [it 's pretty much a sunken ship, sutherland i...  \n",
       "2  [the characters and acting is nothing spectacu...  \n",
       "3  [dead on arrival, the characters stink, subpar...  \n",
       "4  [it is highly derivative and somewhat boring, ...  \n",
       "5  [sadly what follows is not really up to the bu...  \n",
       "6  [probably not, tags on a ridiculous self - rig...  \n",
       "7  [nasty but unamusing joke, is annoying, they c...  \n",
       "8  [a sentimental and painfully mundane european ...  \n",
       "9  [it 's not original , is entirely predictable ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the \"train\" dataset and the port it to pandas\n",
    "train = movie_rationales[\"train\"]\n",
    "df = train.to_pandas()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  1600.000000\n",
       "mean      0.500000\n",
       "std       0.500156\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Open Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Datasets, similar to Hugging Face, its datasets offering allows us to install the library and then load these datasets dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.opendatasets import PublicHolidays\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] read from C:\\Users\\ADMIN\\AppData\\Local\\Temp\\tmptsq2odaf\\https%3A/%2Fazureopendatastorage.azurefd.net/holidaydatacontainer/Processed/part-00000-tid-8468414522853579044-35925ba8-a227-4b80-9c89-17065e7bf1db-649-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today()\n",
    "last_year = datetime.today() - relativedelta(months = 12)\n",
    "hol = PublicHolidays(start_date = last_year, end_date = today)\n",
    "hol_df = hol.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_1816\\4037369736.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  hol_df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryOrRegion</th>\n",
       "      <th>holidayName</th>\n",
       "      <th>normalizeHolidayName</th>\n",
       "      <th>isPaidTimeOff</th>\n",
       "      <th>countryRegionCode</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>563</td>\n",
       "      <td>563</td>\n",
       "      <td>563</td>\n",
       "      <td>32</td>\n",
       "      <td>520</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>38</td>\n",
       "      <td>354</td>\n",
       "      <td>338</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>True</td>\n",
       "      <td>SE</td>\n",
       "      <td>2022-12-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-24 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       countryOrRegion holidayName normalizeHolidayName isPaidTimeOff  \\\n",
       "count              563         563                  563            32   \n",
       "unique              38         354                  338             2   \n",
       "top             Sweden      Søndag               Søndag          True   \n",
       "freq                65          49                   49            23   \n",
       "first              NaN         NaN                  NaN           NaN   \n",
       "last               NaN         NaN                  NaN           NaN   \n",
       "\n",
       "       countryRegionCode                 date  \n",
       "count                520                  563  \n",
       "unique                34                  167  \n",
       "top                   SE  2022-12-25 00:00:00  \n",
       "freq                  65                   37  \n",
       "first                NaN  2022-09-25 00:00:00  \n",
       "last                 NaN  2023-09-24 00:00:00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hol_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryOrRegion</th>\n",
       "      <th>holidayName</th>\n",
       "      <th>normalizeHolidayName</th>\n",
       "      <th>isPaidTimeOff</th>\n",
       "      <th>countryRegionCode</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27456</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Söndag</td>\n",
       "      <td>Söndag</td>\n",
       "      <td>None</td>\n",
       "      <td>SE</td>\n",
       "      <td>2022-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27457</th>\n",
       "      <td>Czech</td>\n",
       "      <td>Den české státnosti</td>\n",
       "      <td>Den české státnosti</td>\n",
       "      <td>None</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2022-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27458</th>\n",
       "      <td>India</td>\n",
       "      <td>Gandhi Jayanti</td>\n",
       "      <td>Gandhi Jayanti</td>\n",
       "      <td>True</td>\n",
       "      <td>IN</td>\n",
       "      <td>2022-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27459</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27460</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Söndag</td>\n",
       "      <td>Söndag</td>\n",
       "      <td>None</td>\n",
       "      <td>SE</td>\n",
       "      <td>2022-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27461</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Tag der Deutschen Einheit</td>\n",
       "      <td>Tag der Deutschen Einheit</td>\n",
       "      <td>None</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27462</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Implantação da República</td>\n",
       "      <td>Implantação da República</td>\n",
       "      <td>None</td>\n",
       "      <td>PT</td>\n",
       "      <td>2022-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27463</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>Dan neovisnosti</td>\n",
       "      <td>Dan neovisnosti</td>\n",
       "      <td>None</td>\n",
       "      <td>HR</td>\n",
       "      <td>2022-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27464</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>Søndag</td>\n",
       "      <td>None</td>\n",
       "      <td>NO</td>\n",
       "      <td>2022-10-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      countryOrRegion                holidayName       normalizeHolidayName  \\\n",
       "27455          Norway                     Søndag                     Søndag   \n",
       "27456          Sweden                     Söndag                     Söndag   \n",
       "27457           Czech        Den české státnosti        Den české státnosti   \n",
       "27458           India             Gandhi Jayanti             Gandhi Jayanti   \n",
       "27459          Norway                     Søndag                     Søndag   \n",
       "27460          Sweden                     Söndag                     Söndag   \n",
       "27461         Germany  Tag der Deutschen Einheit  Tag der Deutschen Einheit   \n",
       "27462        Portugal   Implantação da República   Implantação da República   \n",
       "27463         Croatia            Dan neovisnosti            Dan neovisnosti   \n",
       "27464          Norway                     Søndag                     Søndag   \n",
       "\n",
       "      isPaidTimeOff countryRegionCode       date  \n",
       "27455          None                NO 2022-09-25  \n",
       "27456          None                SE 2022-09-25  \n",
       "27457          None                CZ 2022-09-28  \n",
       "27458          True                IN 2022-10-02  \n",
       "27459          None                NO 2022-10-02  \n",
       "27460          None                SE 2022-10-02  \n",
       "27461          None                DE 2022-10-03  \n",
       "27462          None                PT 2022-10-05  \n",
       "27463          None                HR 2022-10-08  \n",
       "27464          None                NO 2022-10-09  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hol_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryOrRegion</th>\n",
       "      <th>holidayName</th>\n",
       "      <th>normalizeHolidayName</th>\n",
       "      <th>isPaidTimeOff</th>\n",
       "      <th>countryRegionCode</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Descubrimiento de América [Discovery of Americ...</td>\n",
       "      <td>Descubrimiento de América [Discovery of America]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2022-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27504</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Dia de Todos los Santos [All Saint's Day](Obse...</td>\n",
       "      <td>Dia de Todos los Santos [All Saint's Day]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2022-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27511</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Independencia de Cartagena [Independence of Ca...</td>\n",
       "      <td>Independencia de Cartagena [Independence of Ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2022-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>La Inmaculada Concepción [Immaculate Conception]</td>\n",
       "      <td>La Inmaculada Concepción [Immaculate Conception]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2022-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27552</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Navidad [Christmas]</td>\n",
       "      <td>Navidad [Christmas]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2022-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27685</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Día de los Reyes Magos [Epiphany](Observed)</td>\n",
       "      <td>Día de los Reyes Magos [Epiphany]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27729</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Día de San José [Saint Joseph's Day](Observed)</td>\n",
       "      <td>Día de San José [Saint Joseph's Day]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27742</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Jueves Santo [Maundy Thursday]</td>\n",
       "      <td>Jueves Santo [Maundy Thursday]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27749</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Viernes Santo [Good Friday]</td>\n",
       "      <td>Viernes Santo [Good Friday]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27829</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Día del Trabajo [Labour Day]</td>\n",
       "      <td>Día del Trabajo [Labour Day]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27882</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Ascensión del señor [Ascension of Jesus](Obser...</td>\n",
       "      <td>Ascensión del señor [Ascension of Jesus]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27925</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Corpus Christi [Corpus Christi](Observed)</td>\n",
       "      <td>Corpus Christi [Corpus Christi]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27930</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Sagrado Corazón [Sacred Heart](Observed)</td>\n",
       "      <td>Sagrado Corazón [Sacred Heart]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27946</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>San Pedro y San Pablo [Saint Peter and Saint P...</td>\n",
       "      <td>San Pedro y San Pablo [Saint Peter and Saint P...</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27960</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Día de la Independencia [Independence Day]</td>\n",
       "      <td>Día de la Independencia [Independence Day]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Batalla de Boyacá [Battle of Boyacá]</td>\n",
       "      <td>Batalla de Boyacá [Battle of Boyacá]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>La Asunción [Assumption of Mary](Observed)</td>\n",
       "      <td>La Asunción [Assumption of Mary]</td>\n",
       "      <td>None</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023-08-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      countryOrRegion                                        holidayName  \\\n",
       "27475        Colombia  Descubrimiento de América [Discovery of Americ...   \n",
       "27504        Colombia  Dia de Todos los Santos [All Saint's Day](Obse...   \n",
       "27511        Colombia  Independencia de Cartagena [Independence of Ca...   \n",
       "27533        Colombia   La Inmaculada Concepción [Immaculate Conception]   \n",
       "27552        Colombia                                Navidad [Christmas]   \n",
       "27685        Colombia        Día de los Reyes Magos [Epiphany](Observed)   \n",
       "27729        Colombia     Día de San José [Saint Joseph's Day](Observed)   \n",
       "27742        Colombia                     Jueves Santo [Maundy Thursday]   \n",
       "27749        Colombia                        Viernes Santo [Good Friday]   \n",
       "27829        Colombia                       Día del Trabajo [Labour Day]   \n",
       "27882        Colombia  Ascensión del señor [Ascension of Jesus](Obser...   \n",
       "27925        Colombia          Corpus Christi [Corpus Christi](Observed)   \n",
       "27930        Colombia           Sagrado Corazón [Sacred Heart](Observed)   \n",
       "27946        Colombia  San Pedro y San Pablo [Saint Peter and Saint P...   \n",
       "27960        Colombia         Día de la Independencia [Independence Day]   \n",
       "27971        Colombia               Batalla de Boyacá [Battle of Boyacá]   \n",
       "27993        Colombia         La Asunción [Assumption of Mary](Observed)   \n",
       "\n",
       "                                    normalizeHolidayName isPaidTimeOff  \\\n",
       "27475   Descubrimiento de América [Discovery of America]          None   \n",
       "27504          Dia de Todos los Santos [All Saint's Day]          None   \n",
       "27511  Independencia de Cartagena [Independence of Ca...          None   \n",
       "27533   La Inmaculada Concepción [Immaculate Conception]          None   \n",
       "27552                                Navidad [Christmas]          None   \n",
       "27685                  Día de los Reyes Magos [Epiphany]          None   \n",
       "27729               Día de San José [Saint Joseph's Day]          None   \n",
       "27742                     Jueves Santo [Maundy Thursday]          None   \n",
       "27749                        Viernes Santo [Good Friday]          None   \n",
       "27829                       Día del Trabajo [Labour Day]          None   \n",
       "27882           Ascensión del señor [Ascension of Jesus]          None   \n",
       "27925                    Corpus Christi [Corpus Christi]          None   \n",
       "27930                     Sagrado Corazón [Sacred Heart]          None   \n",
       "27946  San Pedro y San Pablo [Saint Peter and Saint P...          None   \n",
       "27960         Día de la Independencia [Independence Day]          None   \n",
       "27971               Batalla de Boyacá [Battle of Boyacá]          None   \n",
       "27993                   La Asunción [Assumption of Mary]          None   \n",
       "\n",
       "      countryRegionCode       date  \n",
       "27475                CO 2022-10-17  \n",
       "27504                CO 2022-11-07  \n",
       "27511                CO 2022-11-14  \n",
       "27533                CO 2022-12-08  \n",
       "27552                CO 2022-12-25  \n",
       "27685                CO 2023-01-09  \n",
       "27729                CO 2023-03-20  \n",
       "27742                CO 2023-04-06  \n",
       "27749                CO 2023-04-07  \n",
       "27829                CO 2023-05-01  \n",
       "27882                CO 2023-05-22  \n",
       "27925                CO 2023-06-12  \n",
       "27930                CO 2023-06-19  \n",
       "27946                CO 2023-07-03  \n",
       "27960                CO 2023-07-20  \n",
       "27971                CO 2023-08-07  \n",
       "27993                CO 2023-08-21  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hol_df[hol_df[\"countryOrRegion\"]==\"Colombia\"] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.opendatasets import Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Anaconda3\\lib\\site-packages\\azureml\\opendatasets\\dataaccess\\_blob_accessor.py:519: Warning: Please install azureml-dataset-runtimeusing pip install azureml-dataset-runtime\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "diabetes = Diabetes.get_tabular_dataset()\n",
    "diabetes_df = diabetes.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22.6</td>\n",
       "      <td>89.0</td>\n",
       "      <td>139</td>\n",
       "      <td>64.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.1897</td>\n",
       "      <td>68</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>160</td>\n",
       "      <td>99.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.9512</td>\n",
       "      <td>82</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>255</td>\n",
       "      <td>185.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.2485</td>\n",
       "      <td>92</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>179</td>\n",
       "      <td>119.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.4773</td>\n",
       "      <td>94</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>180</td>\n",
       "      <td>93.4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.3845</td>\n",
       "      <td>88</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3    S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.00  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.00  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.00  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.00  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.00  4.2905  80  135\n",
       "5   23    1  22.6   89.0  139   64.8  61.0  2.00  4.1897  68   97\n",
       "6   36    2  22.0   90.0  160   99.6  50.0  3.00  3.9512  82  138\n",
       "7   66    2  26.2  114.0  255  185.0  56.0  4.55  4.2485  92   63\n",
       "8   60    2  32.1   83.0  179  119.4  42.0  4.00  4.4773  94  110\n",
       "9   29    1  30.0   85.0  180   93.4  43.0  4.00  5.3845  88  310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AGE, SEX, BMI, BP, S1, S2, S3, S4, S5, S6, Y]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.query(\"BMI < 18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>114</td>\n",
       "      <td>57.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.9512</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>145</td>\n",
       "      <td>72.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.9120</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>191</td>\n",
       "      <td>103.6</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5218</td>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>171</td>\n",
       "      <td>96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.9053</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>163</td>\n",
       "      <td>93.6</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.7377</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>158</td>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.4998</td>\n",
       "      <td>78</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>70.0</td>\n",
       "      <td>162</td>\n",
       "      <td>91.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0254</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX   BMI    BP   S1     S2    S3    S4      S5  S6    Y\n",
       "10    22    1  18.6  97.0  114   57.6  46.0  2.00  3.9512  83  101\n",
       "136   23    1  18.8  78.0  145   72.0  63.0  2.00  3.9120  86   85\n",
       "247   26    1  18.8  83.0  191  103.6  69.0  3.00  4.5218  69   51\n",
       "281   23    2  18.0  78.0  171   96.0  48.0  4.00  4.9053  92   94\n",
       "358   43    1  18.5  87.0  163   93.6  61.0  2.67  3.7377  80   90\n",
       "381   29    2  18.1  73.0  158   99.0  41.0  4.00  4.4998  78  104\n",
       "406   33    1  18.9  70.0  162   91.8  59.0  3.00  4.0254  58   72"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.query(\"BMI < 19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE    7\n",
       "SEX    7\n",
       "BMI    7\n",
       "BP     7\n",
       "S1     7\n",
       "S2     7\n",
       "S3     7\n",
       "S4     7\n",
       "S5     7\n",
       "S6     7\n",
       "Y      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.query(\"BMI < 19\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
